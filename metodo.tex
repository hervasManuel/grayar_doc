\chapter{Método de trabajo}
\label{chap:metodo}

\drop{E}{n} este capítulo se describe la metodología de desarrollo aplicada, sus ventajas y motivo de elección. También se listan y describen todas las herramientas utilizadas en el desarrollo, ya sean hardware o software.

Al final del capitulo se presenta la evolución del proyecto en base a la metodología empleada, los hitos conseguidos en cada fase, su complejidad y el tiempo empleado en cada una de ellas, detallando las iteraciones realizadas hasta conseguir la versión final del sistema. Igualmente se aportará información del rendimiento (profiling) del sistema en diferentes situaciones.

\section{Metodologia del desarrollo}

Hay que tener en consideración la muy diferente naturaleza de los métodos, aunque todos se
engloben dentro de los métodos ágiles. Mientras que Scrum se decanta por la gestión, otros
como XP especifican las prácticas a seguir en el equipo, Pragmatic Programming da pautas
para desarrollar un buen código, algunos como FDD no abarcan la totalidad del proceso de
desarrollo, AgileUP surge como una versión ágil de RUP y propone EUP que es una
ampliación para abarcar todo el ciclo de vida del software, etc.

La visión general facilitará el entendimiento e incluso el poder complementar varios métodos.
Por ejemplo, se podría proponer MSF como marco general, Planguage como lenguaje de
especificación de requisitos, Scrum (con sus patrones organizacionales) como método de
gestión, XP (con patrones de diseño, programación guiada por pruebas y refactorización)
como metodología de desarrollo, RUP como abastecedor de artefactos, ASD como cultura
empresarial y quizá hasta CMM como método de evaluación de madurez.

La aparición de Extreme Programming por parte de Kent Beck en 1999, se considera el punto
de partida de los métodos ágiles. Los métodos ágiles, utilizan prácticas adaptativas (no
basadas en predicciones), iterativas, centradas en la gente (cliente y programadores),
orientadas a entregas incrementales, con mucha comunicación y necesitan que el cliente esté
muy involucrado en el proyecto para recibir su feedback. El feedback continuo es
indispensable para evitar que el cliente, con el software acabado, diga “es lo que pedí, pero
no es lo que necesitaba”, algo habitual cuando se utiliza el método en cascada.

En resumen, las principales características a las que deben dar forma los métodos ágiles son:
• Incremental: versiones pequeñas de software, con ciclos rápidos.
• Cooperativo: desarrolladores y cliente siempre en contacto constante.
• Directo: el método en si es fácil de aprender y modificar, bien documentado.
• Adaptativo: capaz de tolerar los cambios propuestos por el cliente.

2.9.1 Descripción del contexto 
El  equipo  de  desarrollo  lo  constituyen  los  autores  de  este  PFC,  estando  muy 
habituados  a  trabajar  juntos,  con  experiencia  práctica  y  conocimientos  teóricos  en 
metodologías  ágiles.    Debido  al  tamaño  del  equipo  y  condiciones  del  mismo,  las  reuniones 
diarias pierden su utilidad.  
Como ya se ha mencionado, la figura del cliente esta desvirtuada y su función es desempeñada 
por el equipo de desarrollo. 
 Al comienzo de cada iteración el equipo se reunirá y creará el Iteration Backlog que consta de 
un subconjunto de las User Stories del Product Backlog. Estas User Stories son seleccionadas 
atendiendo a las prioridades del cliente. En esta reunión se descompondrá cada User Story del 
Iteration Backlog en tareas, estimando el tiempo necesario para llevarlas acabo. 


2.9.2 Descripción de las prácticas a utilizar 
Las prácticas XP que se van a utilizar son: 
‐ Sentarse juntos 
Todo el desarrollo se llevará a cabo en un espacio que permita un trabajo cercano, cooperativo 
y  que  facilite  la  comunicación  directa.  En  las  ocasiones  en  las  que  ésto  no  sea  posible,  se 
utilizarán medios de videoconferencia como Skype o NetMeeting. 

‐ Iteraciones cortas 
La  primera  iteración  será  de  15  días  de  duración,  y    en  ella  el  equipo  se  familiarizará  con  el 
dominio  de  aplicación  y  las  tecnologías  a  utilizar.  También  se  definirá  en  buena  medida  la 
arquitectura del sistema.  
Las siguientes iteraciones serán de una semana. 
 
‐ Integración continua. 
No se utilizarán herramientas que automaticen este proceso, no obstante, debido al tamaño 
reducido del equipo y a la frecuencia de las integraciones (al menos una al día), esta tarea no 
resultará demasiado compleja. 

 Diseño incremental 
A  pesar  de  definir  buena  parte  de  la  arquitectura  en  las  primeras  iteraciones,  el  diseño  del 
sistema evolucionará iteración tras iteración, sometiéndose a sucesivas refactorizaciones para 
mejorar su calidad.  

 Código compartido 
Esta práctica ha sido utilizada con anterioridad en el equipo de desarrollo. Cualquier miembro 
del mismo podrá introducir cambios en cualquier parte del código para mejorar su calidad. 
Sin olvidar que el presente desarrollo ágil se encuentra en el contexto de la elaboración de un 
PFC,  al  finalizar  cada  iteración  se  destinará  tiempo  a  completar  y  refinar  la  documentación 
obtenida del proceso

2.10.1 Product Backlog de la herramienta 
En  la  tabla  2.1  se  muestra  el  Product  Backlog  de  la  herramienta  que  constituye  la 
especificación completa de la funcionalidad de la misma. Recordemos que esta especificación 
viene determinada por las Historias de Usuario. 
Contiene el nombre de las Historias de Usuario y su identificador, así como la página de este 
PFC en la que se puede encontrar la información detallada de cada una.  

El Product Backlog define todo lo necesario en el producto final, basándose en los
conocimientos de ese momento. Por tanto, define el trabajo a hacer en el proyecto. Incluye
una lista ordenada por prioridades y actualizada de requisitos técnicos para que el sistema se
haga o mejore. Los puntos del Product Backlog, por ejemplo, pueden incluir características,
funciones, parches para bugs, defectos, peticiones de mejoras o actualizaciones de tecnología.
También se incluyen temas que requieren solución para poder hacer otros puntos de la lista. A
la lista de backlog puede contribuir el cliente, el equipo del proyecto y los departamentos de
ventas, marketing y atención al cliente.




2.10.2 Iteraciones 
En este capítulo se presenta toda la documentación generada para gestionar este 
proyecto de desarrollo.  Esta documentación está  estructurada en cuatro iteraciones, tal y 
como se describió en el estudio teórico de las metodologías ágiles.  
En cada iteración se presentará sólo aquella documentación generada en ese intervalo de 
tiempo.  
2.10.2.1 Iteración 1 
La  iteración  1  está  comprendida  entre  el  1  de  julio  y  el  15  de  julio  del  2008.  Es  la 
iteración más larga debido a que en ella se llevan a cabo actividades que no se repetirán en el 
resto  de  iteraciones,  tales  como  familiarización  con  el  dominio  de  aplicación,  especificación 
inicial de la funcionalidad del sistema y esbozo de la arquitectura general del sistema. 
A continuación se mostrará el Backlog de la Iteración, las pruebas y el diseño generado en esta 
iteración. 




3.11.3 Reutilización del código 
Uno  de  los  principales  objetivos  que  se  persiguen  con  las  metodologías  ágiles  es  entregar 
proyectos  en  tiempo  y  bajo  presupuesto.  En  otras  palabras,  se  pretende  minimizar  el  TTM 
(Time To Market) para lo que la reutilización del código constituye un aspecto muy importante, 
no  se  ha  de  perder  tiempo  reinventando  la  rueda  en  cada  proyecto.    Se  ha  de  tratar  de 
obtener  diseños  con  una  alta  modularidad,  reutilizando,  como  cajas  negras,  todos  los 
elementos  software  que  tengamos  y  necesitemos.  De  esta  forma  se  consiguen  sistemas  
modulares en los que se reduce el coste de introducir modificaciones, reduciendo el coste de 
su  mantenimiento;  Por  otro  lado  se  consigue  aumentar  el  repositorio  de  componentes  para 
futuros  proyectos,  con  todas  las  ventajas  que  ello  conlleva  (ver  Desarrollo  Basado  en 
Componentes). 

Se ha de tener en cuenta que no todos los elementos en un proyecto son reutilizables, puesto 
que es inevitable que algunos estén estrechamente ligados a condiciones particulares propias 
de cada dominio de aplicación, la modularidad tampoco ha de convertirse en una obsesión que 
nos obstaculice el avance del proyecto. Recordemos que si se conoce la mejor forma de hacer 
algo,  que  así  se  haga,  sino  que  se  haga  de  la  mejor  forma  conocida  para  la  que  se  tenga 
tiempo. 
  
Puede parecer que un diseño iterativo e incremental es incompatible con un diseño modular 
cuyos  componentes presenten bajo acoplamiento y alta cohesión. La introducción de la User 
Story  “ver  contexto  (User  Story)  de  la  información”,  que  inicialmente  no  se  contemplaba 
dentro de la funcionalidad del sistema (Product Backlog), constituye un síntoma de un diseño 
altamente modular, que a pesar de ser creado de  manera iterativa e incremental, respondió 
bien  a  los  cambios.  Debido  a  que  su  implementación  requirió  introducir  pequeñas 
modificaciones en componentes en los que en ningún caso varió la estructura de los mismos. 
Dichos  elementos  fueron:  “amtlist”,  “amttable”  y  la  creación  de  una  nueva  pantalla  en  la 
interfaz de grafica de usuario (elemento “amtui”). 




\section{Tecnologias y herramientas utilizadas}

En esta sección se listan y detallan los recursos software y hardware empleados en la construcción de la plataforma. Además de una breve explicación del recurso, se enuncia la versión utilizada y sobre qué plataformas opera.

\subsection{Lenguajes}
\begin{itemize}
\item \textbf{C++} - El lenguaje empleado para el desarrollo del proyecto ha sido C++ [Str13], debido a la eficiencia y velocidad de ejecución que proporciona a la hora trabajar en aplicaciones y sistemas en tiempo real. También por ser el estándar referente en bibliotecas gráficas y de visión artificial.
\end{itemize}

\subsection{Hardware}
\begin{itemize}
\item Como plataforma hardware del sistema se dispondrá de una placa Raspberry Pi, 
\item una cámara USB, 
\item una cámara Raspberry Pi Board conectada a través de un cable plano de 15 pines MPI al puerto CSI (Camera Serie Interface) de la placa.
\item un pico-proyector portátil 
\item Amplificador de Audio LM386 montado en una placa de test con un altavoz de 1W
\item Dos equipos informáticos para el desarrollo del proyecto. Intel Core i7-2600K 3.4 GHz 4 nucleos y dos hilos por nucleo 16 GB de RAM y Nvidia GeForce GTX 560 Ti

\end{itemize}

\subsection{Software}
\subsubsection{Sistemas Operativos}

\begin{itemize}
\item \textbf{Debian} - Es una distribución de GNU/Linux desarrollada y mantenida por una comunidad de voluntarios. Es una de las famosas y un gran número de distribuciones estan basadas en ella. Para el desarrollo del proyecto se ha utilizado la versión \emph{unstable}. 

\item \textbf{Raspbian} - Es una distribución de GNU/Linux basada en Debian Wheeze especialmente diseñada y optimizada para la ejecución en la placa Raspberry Pi con  CPU ARMv6   
\end{itemize}

\subsubsection{Aplicaciones de desarrollo}
\begin{itemize}
\item \textbf{GNU Emacs} - Editor y entorno de desarrollo. Se ha utilizado la generación del código fuente y la escritura de la documentación. Versión 24.3.1
\item \textbf{GNU Make} - Herramienta para la compilación incremental, con soporte multiproceso.
\item \textbf{GNU GCC} - La colección de compiladores GNU. En concreto se ha utilizado el compilador de C++ (g++) en su versión 4.5.2.
\item Make: se ha utilizado para crear el sistema de Makefiles de compilación que facilita el proceso. La versión instalada es la 3.81.
\item \textbf{GNU GDB} - se trata del depurador por excelencia de los sistemas GNU/Linux. Se ha utilizado la versión 7.2.
\item \textbf{GNU GPROF} - es una herramienta para hacer profiling (ver Sección 6.2) para compiladores de la familia gcc. Se ha utilizado la versión 2.21.
\item \textbf{GNU CMAKE} - se trata de una herramienta análoga a make, aunque de más alto nivel, para la automatización de generación de código. Se ha utilizado principalmente para la compilación de la biblioteca Bullet. La versión de CMake es la 2.8.3. 
\end{itemize}




\subsubsection{Documentación y gráficos}
\begin{itemize}
\item \textbf{Doxygen} - Sistema de documentación de código fuente [dox10]. Compatible con C++. Se ha utilizado para realizar el manual de referencia de MARS.

\item \textbf{InkScape} - Programa de edición de imágenes vectoriales.

\item \textbf{GIMP} - Herramienta de manipulación de gráficos, utilizada para la creación de overlays para OGRE3D y gráficas de módulos. Versión 2.6.12.

\item \textbf{LibreOffice Draw} - Potente herramienta de dibujado vectorial perteneciente a la suite ofimática LibreOffice. Utilizada para la generación de diagramas para la documentación. Versión 3.5.4.

\item \textbf{LibreOffice Calc} - Potente hoja de cálculo perteneciente a la suite ofimática LibreOffice. Utilizada para el análisis de resultados de la red neuronal empleada, datos estadísticos, generación de gráficas, comparación de valores. . . Versión 3.5.4.
\item \textbf{\LaTeX{}} - Es un sistema de composición de textos, orientado especialmente a la creación de libros, documentos científicos y técnicos que contengan fórmulas matemáticas. Elegido para la generación de la documentación mediante la distribución Texlive. Versión 2009-15.
\end{itemize}


\subsubsection{Bibliotecas}
\begin{itemize}
\item \textbf{OpenCV} - Biblioteca libre que proporciona funciones dirigidas principalmente para el desarrollo de aplicaciones de visión por computador en tiempo real. La versión utilizada es la 2.4.9
\item \textbf{RapidXML} - 
\item \textbf{RaspiCam} -  Es una biblioteca para la utilización de la cámara Raspberry Pi Board desarrollada en C++ por el grupo de investigación ``Aplicaciones de la Visión Artificial'' de la Universidad de Cordoba. La versión utilizada es la 0.1.1 
\end{itemize}

\subsubsection{Control de Versiones}
\begin{itemize}
\item \textbf{Git} - Sistema de control de versiones distribuido. Como repositorio central se ha utilizado la plataforma Bitbucket.
\end{itemize}

\section{Evolución del proyecto}
\subsection{Concepto del software}
\subsection{Análisis preliminar de requisitos}
\subsection{Diseño general}
\subsection{Iteraciones}

\subsubsection{Iteracion 0}
Como punto de partida para la elaboración del estado del arte se realizo una revisión sistemática de las diferentes técnicas para la identificación de documentos y su recuperación de una base de datos. Como resultado de esta revisión se ha podido conocer las técnicas más empleadas, así como sus ventajas e inconvenientes. 

El claro ganador es LLAH (Locally Likely Arrangement Hashing) con casi un 40\% de utilización ya sea con su implementación inicial o implementaciones optimizadas creadas para salvar las limitaciones del algoritmo original, lo que lo hace aún mas potente y versatil.

Aunque los metodos basados en detección de descriptores de caracteristicas invariantes como SIFT, SURF, aparecen como muy utilizados, realmente no funcionan correctamente en identificación de documentos ya que no presentan zonas de textura y se producen repeticiones de patrones binarios (el propio texto cumple este patron). La mayoria son una variación del proceso inspirado en la metodologia de Lowe [SIFT], y en la que se obtienen buenos resultados sobre documentos semiestructurados realizando una selección de puntos extraidos y una adaptación del algoritmo RANSAC para la validación de supuestos aciertos en la comparación. El algoritmo tiene una tasa elevada de recuperación y precisión, es robusto a las deformaciones que pueda tener la imagen (perspectiva) y no necesita ningun paso previo de segmentación pero, como inconvenientes, no funciona ante grandes secciones de texto y la identificación que realiza es para obtener documentos similares (un ticket, un billete de tren,....) a la imagen utilizada como consulta.

Uno de los puntos del analisis de resultados, indica que al utilizar hardware con distinto rendimiento, es dificil tener mediciones normalizadas para todos los métodos. Como trabajo futuro se puede realizar para el gestor documental, la implementación de varios de los metodos mas utilizados y ofrecer un estudio comparativo completo al ejecutarse en la misma plataforma.

Existen varias implementaciones optimizadas sobre LLAH para salvar las limitaciones iniciales del algoritmo. Sería un trabajo futuro la tarea de buscar sólo las publicaciones que se hayan hecho sobre LLAH e intentar crear una implementación conjunta  con todas las optimizaciones. 


\subsubsection{Iteración 1}
\begin{description}
\item [Arquitectura básica] Una vez conocidas las técnicas necesarias y los objetivos del sistema a desarrollar construimos una arquitectura básica que iremos completando y refinando en cada una de las sucesivas iteraciones.
\item [Captura de imágenes] La raspberry tiene opción de conectar una cámara USB u obtener las ímagenes por medio de una raspiCam, que se conecta por directamente a un puerto de expansión de la placa. Se crea un módulo de captura de imagenes que soporte ambas cámaras.

\item [Calibrado de la cámara] Diseñamos y construimos un sistema de calibrado para obtener los parametros intrínsecos de la cámara, necesarios para los cálculos posteriores de posicionamiento.

\item [Detección de un folio en la imagen] Mediante segmentación de la imagen obtenida, detectamos una hoja de papel y obtenemos la posición de sus 4 esquinas.

\item [Sistema básico de cálculo de homografias] Creamos un sistema básico de cálculo homogŕafico necesario para la proyección de la perspectiva. En esta primera fase, los cálculos son los
  necesarios para realizar el registro y visualizarlo en la pantalla del ordenador.

\end{description}

\subsubsection{Iteración 2}
\begin{description}
\item [Cálculo de homografias del sistema cámara-proyector] Un proyector se calibra usando los mismos algoritmos de calibración que una cámara ya que puede considerarse como una ``cámara inversa''. Sin embargo como el proyector no ve, el método no es tan directo como en el caso de una cámara.
Para la calibración de un proyector es inevitable el uso al menos de una cámara. Para calibrar un proyector, es necesario obtener un conjunto de coordenadas 3D-2D correspondientes. Las coordenadas pueden determinarse usando una cámara situada en una posición con una vista similar a la que tendria el proyector. El método consiste en proyectar con el proyector un plano de calibración y establecer la correspondencia entre lo proyectado y lo que vé la camara.

\end{description}

\subsubsection{Iteración 3}
\begin{description}
\item [Optical Flow] Para la estimación y descripción del movimiento, se implementa Optical Flow  (Lucas-Kanade) que nos va a proporcionar herramientas para detección, segmentación y seguimiento de  objetos móviles en la escena a partir de un conjunto de imágenes. 

\end{description}
\subsubsection{Iteración 4}
\begin{description}
\item [Detector de documentos mediante descriptores de imagenes] Se realiza la implementación de detección de documentos mediante descriptores de imagenes. En esta fase se ha utilizado SURF.
\item [Dibujado mediante OpenCV] Se realizan una serie de funciones para dibujado mediante OpenCV para servir de modo debug ya que permite recibir una ventana con la imagen por medio de SSH.
\end{description}

\subsubsection{Iteración 5}
\begin{description}
\item [Historico de percepciones] Al igual que en ARToolKit, se desarrolla una función de tratamiento del histórico de percepciones para estabilizar el tracking. Este histórico se implementa  almacenando las últimas 10 percepciones similares y realizando una media ponderada en la que las percepciones recientes tienen más peso que las antiguas. Para determinar si son percepciones próximas se establece un umbral. Mediante el uso de esta técnica eliminanos gran parte del efecto tembloroso en la proyección.
\end{description}

\subsubsection{Iteración 6}
\subsubsection{Iteración 7}


\section{Recursos y costes}
\subsection{Coste económico}
\subsection{Estadísticas del repositorio}
\subsection{Profiling}