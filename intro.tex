\chapter{Introducción}
\drop{D}{esde} la introducción del ordenador personal en la década de los años 80, los esfuerzos por naturalizar la experiencia de la interación ha estado limitada por el factor de adaptación de una persona a los distintos entornos informáticos. A día de hoy, todavia conservamos el mismo esquema de utilización de un ordenador de sobremesa de principios de los 80, con computadores que todavia tienen prácticamente la misma configuracion de monitor, teclado y ratón. Realmente no hay nada de natural en este tipo de experiencia de usuario, y en todo caso es lo más alejado de ser una funcion natural humana. Para apoyar aún más lo lejos que nos hemos desviado de la naturaleza, el estudio de la ergonomía surgió como una manera de minimizar en nuestros cuerpos el riesgo de una lesión, ya que tratamos de adaptarlos a este entorno no natural.

Afortunadamente estamos en una época en la que estamos rompiendo con los paradigmas tradicionales establecidos. La introducción de nuevas formas de relacionarnos con los ordenadores esta haciendo que vean la luz dispositivos portatiles, superficies multitáctiles,... donde estamos dejando las limitaciones de los entornos virtuales y metaforas obsoletas. Ya es hora de que volvamos a nuestro mundo natural.

\section{Un poco de historia}
Los computadores hasta los años 70 no eran mucho más que grandes calculadoras utilizadas para automatizar cálculos complejos en instituciones militares y para investigación de alto nivel. Las primeras interfaces consistian en introducir una serie de tarjetas perforadas que contenian el programa codificado y mas tarde revisar en un impresora el resultado de la ejecución.

Posteriormente se desarrollaron las interfaces de línea de comandos (CLI), así el usuario ya no tuvo que perforar tarjetas ni tenía que esperar. Los programadores y usuarios disponian de acceso a un terminal, y la usaban para interactuar directamente con el ordenador en algo parecido a lo que podemos denominar ``tiempo real''. El usuario podía introducir una orden, y obtener una salida textual de vuelta más o menos inmediata.

Fue a principios de los años 80, cuando la informática personal dio un gran salto mediante la interfaz gráfica de usuario (GUI), que era una forma más natural y convincente para interactuar con un ordenador. Esto hizo que la informática fuese más accesible para la gente, dandole la capacidad de comunicarse con el ordenador a base de metáforas de escritorio, ventanas y punteros de ratón.

Pero en los 30 años desde el lanzamiento del primer ordenador en ofrecer una interfaz gráfica de usuario en una máquina de bajo coste, la experiencia física de la interacción no ha sufrido muchos cambios en lo que se refiere a ordenadores personales. En este tiempo se inventó la Web, progresó desde su primera iteración hasta el actual HTML 5, desarrollamos multitud de revolucionarias plataformas web para conectar y relacionarnos por todo el mundo, pero mantenemos nuestra rígida adhesión al legado del monitor, ratón y teclado a principios de 2010 como lo fue en la década de los 80. 

\section{Volviendo a lo natural}
No es hasta finales de los años 2000, cuando podemos decir que empieza la ``era post-PC''. La generalización de los dispositivos multi-touch y la informática móvil marca uno de los mayores hitos en las interfaces persona-computador. Los dispositivos móviles se diseñan para ser ligeros, portátiles y encajar con el estilo de vida de una persona. De repente, estamos en medio de una de las más importantes revoluciones tecnológicas, cuando nuestros dispositivos informáticos comienzan a adaptarse a nuestras funciones naturales de ser humano.

El primer paso en este ámbito ha sido la amplia adopción de la tecnología móvil inteligente en funciones cotidianas, como por ejemplo, el control de una agenda con los planes del día o saber a dónde ir, independientemente del sentido de orientación que tengamos. El conocimiento aparece en el momento que sacamos el smartphone en busca de las respuestas.

Apenas estamos comenzando a descubrir las posibilidades de un mundo en el que los dispositivos se adaptan a nuestras conductas y la tecnología apoya y amplifica nuestras funciones humanas naturales. Estamos en el camino de lo que podemos llamar ``computacion humana'' cuando el hardware desaparezca o nos pasará desapercibido que realmente estamos interaccionado con una ordenador. Esto ocurre cuando la tecnología se integra discretamente en objetos cotidianos o en funciones naturales del ser humano. La tecnología será la que se adapte a nosotros, en lugar de ser los seres humanos quienes se adapten a la computación y la máquina aprendida a reconocer e interpretar los patrones humanos para producir una salida basada en un contexto familiar.

Un ejemplo de una tecnología no relacionada con la computación que ha madurado con el tiempo, es la optometría. Basta con pensar en las lentes de contacto. Se coloca una capa fina directamente en nuestra córnea, alterando así los rayos de luz que convergen perfectamente en nuestra retina. Al instante, sin apenas esfuerzo, tenemos una visión perfecta. Una vez colocadas tendemos a olvidar que las llevamos puestas y esto se debe a su perfecta integración en nuestro estilo de vida cotidiana. 

Para reflexionar sobre el estado actual de la informática en relación a la optometría: imaginemos que dependiesemos de un teclado y un ratón para modificar nuestra vista cada vez que necesitasemos enfocar.

\section{Interfaces naturales basadas en vision artificial}
\emph{Interfaz natural de usuario} es un término genérico para una variedad de tecnologías que permiten a los usuarios interactuar con los ordenadores en términos humanos. Algunas de estas tecnologias son las basadas en visión por computador y que que son capaces desde interpretar expresiones naturales del ser humano como gestos hasta porporcionar información contextual que se proyecta dentro del campo de vision del usuario, como pretenden las Google Glass. 

Las interfaces de usuario basadas en vision por computador llevan varios años desarrollandose y comercialiazandose con éxito dentro de la industria del videojuego. Mediante un dispositivo externo permite a los usuarios controlar e interactuar con la consola sin necesidad de tener contacto físico con un controlador de videojuegos tradicional, reconociendo gestos, comandos de voz, objetos e imágenes.

\subsection{EyeToy}
El EyeToy es un cámara que fue lanzada en octubre de 2003 para la PlayStation 2. Este dispositivo utiliza visión por computador y reconocimiento de gestos para procesar las imágenes adquiridas por la cámara y permite a los jugadores interactuar con los juegos.

La estetica de los juegos que soportaban este sistema consistian en la introducción del jugador mediante realidad mixta solo que interactúe en la pantalla y que sea el personaje en el que se basa la historia del juego. 

Este tipo de interación supuso una revolución en la forma de interactuar con los videojuegos y ha sido el precusor de otros dispositivos como Kinect.

\subsection{Kinect}
Inu puede ser también combinaciones de estos diferentes tipos de tecnología. Por ejemplo, la combinación de la palabra y los gestos del cuerpo / la mano se utiliza en el sensor de Microsoft Xbox Kinect. Microsoft, ha abierto el sensor con APIs gratuitas y SDK para el desarrollo de software habilitado para NUI para Windows utilizando el sensor Kinect para Ventanas. El Kinect es un sensor que se vendió previamente como un periférico opcional para la Xbox y que ahora es una parte incluida de la nueva Xbox Una consola de juegos y entretenimiento en el hogar.

Este dispositivo especial cuenta con dos cámaras de visión artificial estéreo con la percepción de profundidad. Software en el dispositivo puede distinguir extremidades, expresiones faciales, gestos con las manos, movimientos de las extremidades y los dedos, movimientos faciales, expresiones faciales, incluso el pulso del usuario, y utilizarlos como insumos para el control. Múltiples micrófonos están presentes para cancelación de ruido y para el reconocimiento de la direccionalidad del sonido. No es un software a bordo para el reconocimiento de voz y facial para usuario recognition.The controla el juego por las entradas de voz y moviendo su cuerpo y las manos.

Esto representa una forma más natural de interactuar y da vida a algunos de estos modelos de interacción humano-computadora que prevee la ciencia ficción anterior. No es difícil de forsee posibles aplicaciones a la formación con esto, especialmente con las API del dispositivo abierto para el desarrollo comercial y la investigación. Los siguientes enlaces y el vídeo a continuación dan una idea de lo que se está haciendo con esta herramienta sensor.

\section{Realidad Aumentada}
La realidad aumentada se podría considerar como la aplicación de distintas técnicas de visión por computador, mediante la cual la percepción del mundo real se complementa con información adicional generada por ordenador en tiempo real. Esta información adicional puede ser desde etiquetas virtuales, representaciones de modelos tridimensionales, o incluso cambios de iluminación. 

El principal problema que deben tratar los sistemas de realidad aumentada se considera \textbf{registro}, que consiste en calcular la posición relativa de la cámara respecto a la escena para colocar correctamente las imágenes sintéticas dentro de la imagen real. Los objetos del mundo real y virtual deben estar perfectamente alineados o la sensación de integración se verá seriamente afectada.

La realidad aumentada se puede aplicar a prácticamente todos los campos. En el sector industrial, para la reparación y mantenimiento de máquinas e instalaciones complejas, visualización de datos o simulación.  En aplicaciones médicas, mostrarían la situación de órganos no visibles durante una cirugía. También se han realizado aplicaciones para diseño de interiores (IKEA), presentaciones de productos, educación, publicidad, turismo, arte y ocio. 
En el siguiente paso de esta revolución, el hardware tenderá prácticamente a desaparecer. Con las Google Glass como ejemplo, la intención es la de liberarnos de tener la sensacion de manejar un ordenador personal ofreciendonos una capa de presentación sobre nuestro campo de vision. 

Las aplicaciones de Realidad Aumentada deben cumplir las siguientes características definidas por Ronald T. Azuma \cite{Azuma}:

\begin{description}
\item[Combinar el mundo real con el virtual.] El resultado final debe mostrar la información sintética sobre las imágenes percibidas del mundo real.
\item[Debe ser interactivo en tiempo real.] La integración debe ser realizada \emph{en el momento}, por lo que el cálculo necesario debe realizarse en el menor tiempo posible.
\item[La alineación de los elementos virtuales debe realizarse en 3D.] Los objetos sintéticos deben de estar correctamente alineados en el espacio tridimensional,  o la sensación de integración se verá seriamente afectada.
\end{description}

\section{Realidad Aumentada Espacial}
  El aumento de las prestaciones y la reducción de los costes hacen que los proyectores se hayan popularizado y establecido como herramientas habituales para la visualización. La capacidad de generar imágenes mucho mayores que el propio dispositivo prácticamente en cualquier lugar es una característica interesante para muchas aplicaciones que no pueden ser mostradas en pantallas convencionales. 

Existen actualmente muchas líneas de investigación sobre este tema, en las que se pretende aplicar este potencial mediante la utilización de los proyectores de una manera poco convencional y desarrollar nuevas e innovadoras pantallas de información que van más allá de presentaciones en las típicas pantalla planas.
 
%Con display de proyector-han reemplazado claramente pantallas frontales adjunto para más de realidad virtual (VR) aplicaciones. Aparece la pantalla envolvente inmersivo y configuraciones de pared similares o de mesa como semi-inmersivos se utilizan para la visualización de contenido gráfico bidimensional o tridimensional. 

Hoy en día, la mayoría de las aplicaciones de realidad aumentada se centran en la movilidad. De este modo, las pantallas de dispositivos portátiles y los smartphones se han convertido en la opcion dominantes para la visualización. Sin embargo, existe una tendencia creciente hacia la presentación mediante proyectores para realidad aumentada. 

Los enfoques de realidad aumentada basada en proyectores combinan las ventajas de la realidad virtual y la realidad aumentada porporcionando sensaciones inmersivas y aumentadas se pueden realizar sobre entornos cotidianos, sin la necesidad de pantallas de proyección especiales y configuraciones de pantalla dedicadas. Para muchas aplicaciones, esto requiere la perdida de la movilidad, pero no necesariamente de la portabilidad. Otras aplicaciones, sin embargo, no requieren movilidad y más bien se benefician de las propiedades aumentadas que proporciona la proyección. Los ejemplos van desde entretenimiento educativo en los museos, con proyecciones sobre paredes o sobre las propias obras de arte, hasta proyecciones en fachadas de edificios históricos para conseguir efectos de movimiento ó 3D, dando lugar a un espectáculo artístico conocido como \emph{projection mapping.}

\section{Impacto socio-económico}

\section{Motivación}
  El presente proyecto se enmarca dentro de la Cátedra Indra-UCLM, en el proyecto “ARgos: Sistema de Ayuda a la Gestión Documental basado en Visión por Computador y Realidad Aumentada” que tiene como objetivo la construcción de un sistema de ayuda a la gestión de documentos, basado principalmente en visión por computador y síntesis visual y auditiva en el espacio físico, empleando técnicas de realidad aumentada.  
  
  El proyecto Argos está pensado para facilitar la integración laboral de cualquier persona con necesidades especiales que tenga que gestionar documentación impresa. 
  
  Todos los países de la Unión Europea aceptan las recomendaciones generales de la Organización Mundial de la Salud así como las directrices y programas de las Naciones Unidas relativas a las personas con discapacidad.  En especial, las políticas nacionales tomaron como principal referencia el Programa de Acción Mundial para los Impedidos, aprobado por la Asamblea General de las Naciones Unidas en 1982 y que proponía expresamente «la participación plena de los individuos con discapacidad en la vida social, con oportunidades iguales a las de toda la población». 

  Podemos partir de las personas en edad laboral que presentan discapacidades para las actividades de la vida diaria, para analizar su grado de severidad y observar que, a excepción de una discapacidad total, de manera que están impedidas absolutamente para realizar las acciones correspondientes, las personas con discapacidad pueden realizar las acciones correspondientes, normalmente gracias a la ayuda de aparatos o de procesos específicos de adaptación del puesto de trabajo.
  

 
  \section{Estructura del documento}

  Este documento se ha estructurado según las indicaciones de la normativa de trabajos de fin de grado de la Escuela Superior de Informática de la Universidad de Castilla-La Mancha, y contará con los siguientes capítulos:
  \begin{definitionlist}
  \item[Capítulo \ref{chap:objetivos}: \nameref{chap:objetivos}] Finalidad y justificación  (con todo detalle) del presente documento.
  \item[Capítulo \ref{chap:antecedentes}: \nameref{chap:antecedentes}] Explica herramientas y aspectos básicos de edición con \LaTeX.
  \item[Capítulo \ref{chap:metodo}: \nameref{chap:metodo}] Explica herramientas y aspectos básicos de edición con \LaTeX.
  \item[Capítulo \ref{chap:resultados}: \nameref{chap:resultados}] Explica herramientas y aspectos básicos de edición con \LaTeX.
  \item[Capítulo \ref{chap:conclusiones}: \nameref{chap:conclusiones}] Explica herramientas y aspectos básicos de edición con \LaTeX.
  \end{definitionlist}



  % Local Variables:
  % coding: utf-8
  % mode: latex
  % mode: flyspell
  % ispell-local-dictionary: "castellano8"
  % End:
